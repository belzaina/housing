---
title: "PLTR Robustness Check"
author: 
   - ZAINAB BELGADA^[Institut d'Economie d'Orleans, zainab.belgada@etu.univ-orleans.fr]
   - DAMIEN ZINSOU^[Institut d'Economie d'Orleans, zinsou.mezonlin@etu.univ-orleans.fr]
date: "15/01/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
library(magrittr)
library(ggplot2)
```

# Introduction

In this notebook, we compute the average value of each evaluation metric across the 5 x 2 cross-validation test samples. We compare the performance of PLTR to that of:

- Random Forest
- SVM with both radial and polynomial kernel
- Linear Logistic regression without and with regularization (RIDGE, LASSO, and Adaptive LASSO)
- Penalized Non-Linear Logistic Regression which include as additional variables quadratic and interaction terms (RIDGE, LASSO, and Adaptive LASSO) 

# Load and Prepare the Housing Dataset

We will begin by loading some helper functions that are implemented in the `scripts` folder before reading the raw housing dataset:

```{r, echo=TRUE, cache=TRUE}
source("./../../scripts/prepare_housing_dataset.R")
source("./../../scripts/add_interaction_quadratic_terms.R")

# Load The Raw Dataset
raw_housing_dataset <- readxl::read_excel("./../../data/hmeq.xls", sheet = 'hmeq')
```

Next, we will prepare 3 versions of the dataset:

- `clean_housing_dataset`: Missing value are imputed. Categorical predictors are one-hot encoded.
- `clean_housing_dataset_factor` : Will be used only for in Non-Penalized Linear Logistic Regression. Instead of one-hot encoding, categorical predictors are represented as R's factor datatype in order to avoid multicollinearity. 
- `clean_with_interaction_quadratic`: Will be used for Non-Linear Logistic Regression. As the name suggests, this dataset include as additional variables quadratic and interaction terms.

```{r, echo=TRUE, cache=TRUE}
clean_housing_dataset <- prepare_housing_dataset(raw_housing_dataset)

clean_housing_dataset_factor <- prepare_housing_dataset(raw_housing_dataset, 
                                                        to_dummy = FALSE)

clean_with_interaction_quadratic <- add_interaction_quadratic_terms(clean_housing_dataset)
```

# Data Partitioning for Cross Validation

Following Dumitrescu et al. (2020), we use the so called N x 2-fold cross-validation of Dietterich (1998), which involves randomly dividing the dataset into two sub-samples of equal size:

- The first (second) part is used to build the model;
- The second (first) part is used for evaluation. 

This procedure is repeated N times, and the evaluation metrics are averaged. We set N = 5 for computational reasons.

```{r, echo=TRUE, cache=TRUE}
source("./../../scripts/partition_data.R")

# For:
# PLTR, RANDOM FOREST, SVM, PENALIZED LINEAR LOGISTIC REGRESSION
data_partitions_ml <- partition_data(clean_housing_dataset, N = 5, random_seed = 8080)

# For LINEAR LOGISTIC REGRESSION
data_partitions_llr <- partition_data(clean_housing_dataset_factor, N = 5, 
                                      random_seed = 8080)

# For PENALIZED NON-LINEAR LOGISTIC REGRESSION
data_partitions_nllr <- partition_data(clean_with_interaction_quadratic, N = 5, 
                                       random_seed = 8080)
```

# Cross Validation Results

Loading some helper functions:

```{r, echo=TRUE, cache=TRUE}
source("./../../scripts/compute_evaluation_criteria.R")
source("./../../scripts/cross_validate.R")
source("./../../scripts/rules_utilities.R")
source("./../../scripts/pltr_learner.R")
source("./../../scripts/random_forest_learner.R")
source("./../../scripts/svm_learner.R")
source("./../../scripts/logistic_learner.R")
source("./../../scripts/penalized_learner.R")
```

## 1. PLTR - Adaptive LASSO

In order to save some computation time, we will first generate predictors pairs upfront:

```{r, echo=TRUE, cache=TRUE}
predictors_set <- clean_housing_dataset %>% 
   names() %>% 
   tail(n = -1)

predictors_pairs <- predictors_set %>% 
   combn(m = 2) %>%
   purrr::array_branch(margin = 2)
```

Running 5 x 2-fold cross validation:

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
pltr_alasso_results <- cross_validate(
   cv_partitions = data_partitions_ml, 
   learner = pltr_learner, 
   evaluator = compute_evaluation_criteria,
   shinyProgress = FALSE,
   predictors_pairs = predictors_pairs, 
   penalty = 2)
```

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
pltr_alasso_avg_results <- pltr_alasso_results %>%
   dplyr::select(AUC, GINI, PCC, BS, KS) %>%
   colMeans() %>%
   dplyr::bind_rows() %>%
   dplyr::mutate(LEARNING_ALGORITHM = "PLTR (ADAPTIVE LASSO)") %>%
   dplyr::relocate(LEARNING_ALGORITHM, .before = AUC)

pltr_alasso_avg_results
```

## 2. PLTR - LASSO

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
pltr_lasso_results <- cross_validate(
   cv_partitions = data_partitions_ml, 
   learner = pltr_learner, 
   evaluator = compute_evaluation_criteria,
   shinyProgress = FALSE,
   predictors_pairs = predictors_pairs, 
   penalty = 1)
```

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
pltr_lasso_avg_results <- pltr_lasso_results %>%
   dplyr::select(AUC, GINI, PCC, BS, KS) %>%
   colMeans() %>%
   dplyr::bind_rows() %>%
   dplyr::mutate(LEARNING_ALGORITHM = "PLTR (LASSO)") %>%
   dplyr::relocate(LEARNING_ALGORITHM, .before = AUC)

pltr_lasso_avg_results
```

## 3. PLTR - RIDGE

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
pltr_ridge_results <- cross_validate(
   cv_partitions = data_partitions_ml, 
   learner = pltr_learner, 
   evaluator = compute_evaluation_criteria,
   shinyProgress = FALSE,
   predictors_pairs = predictors_pairs, 
   penalty = 0)
```

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
pltr_ridge_avg_results <- pltr_ridge_results %>%
   dplyr::select(AUC, GINI, PCC, BS, KS) %>%
   colMeans() %>%
   dplyr::bind_rows() %>%
   dplyr::mutate(LEARNING_ALGORITHM = "PLTR (RIDGE)") %>%
   dplyr::relocate(LEARNING_ALGORITHM, .before = AUC)

pltr_ridge_avg_results
```

## 4. Random Forest

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
rf_results <- cross_validate(
   cv_partitions = data_partitions_ml, 
   learner = random_forest_learner, 
   evaluator = compute_evaluation_criteria,
   random_seed = 8081,
   shinyProgress = FALSE)
```

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
rf_avg_results <- rf_results %>%
   dplyr::select(AUC, GINI, PCC, BS, KS) %>%
   colMeans() %>%
   dplyr::bind_rows() %>%
   dplyr::mutate(LEARNING_ALGORITHM = "RANDOM FOREST") %>%
   dplyr::relocate(LEARNING_ALGORITHM, .before = AUC)

rf_avg_results
```

## 5. SVM: Radial Kernel

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
svm_radial_results <- cross_validate(
   cv_partitions = data_partitions_ml, 
   learner = svm_learner, 
   evaluator = compute_evaluation_criteria,
   kernel = "radial",
   shinyProgress = FALSE)
```

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
svm_radial_avg_results <- svm_radial_results %>%
   dplyr::select(AUC, GINI, PCC, BS, KS) %>%
   colMeans() %>%
   dplyr::bind_rows() %>%
   dplyr::mutate(LEARNING_ALGORITHM = "SVM (RADIAL)") %>%
   dplyr::relocate(LEARNING_ALGORITHM, .before = AUC)

svm_radial_avg_results
```

## 6. SVM: Polynomial Kernel

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
svm_polynomial_results <- cross_validate(
   cv_partitions = data_partitions_ml, 
   learner = svm_learner, 
   evaluator = compute_evaluation_criteria,
   kernel = "polynomial",
   shinyProgress = FALSE)
```

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
svm_polynomial_avg_results <- svm_polynomial_results %>%
   dplyr::select(AUC, GINI, PCC, BS, KS) %>%
   colMeans() %>%
   dplyr::bind_rows() %>%
   dplyr::mutate(LEARNING_ALGORITHM = "SVM (POLYNOMIAL)") %>%
   dplyr::relocate(LEARNING_ALGORITHM, .before = AUC)

svm_polynomial_avg_results
```

## 7. Linear Logistic Regression

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
llr_results <- cross_validate(
   cv_partitions = data_partitions_llr, 
   learner = logistic_learner, 
   evaluator = compute_evaluation_criteria,
   shinyProgress = FALSE)
```

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
llr_avg_results <- llr_results %>%
   dplyr::select(AUC, GINI, PCC, BS, KS) %>%
   colMeans() %>%
   dplyr::bind_rows() %>%
   dplyr::mutate(LEARNING_ALGORITHM = "LINEAR LR") %>%
   dplyr::relocate(LEARNING_ALGORITHM, .before = AUC)

llr_avg_results
```

## 8. Penalized Linear Logistic Regression: RIDGE

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
llr_ridge_results <- cross_validate(
   cv_partitions = data_partitions_ml, 
   learner = penalized_learner, 
   evaluator = compute_evaluation_criteria,
   penalty = 0,
   shinyProgress = FALSE)
```

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
llr_ridge_avg_results <- llr_ridge_results %>%
   dplyr::select(AUC, GINI, PCC, BS, KS) %>%
   colMeans() %>%
   dplyr::bind_rows() %>%
   dplyr::mutate(LEARNING_ALGORITHM = "LINEAR LR (RIDGE)") %>%
   dplyr::relocate(LEARNING_ALGORITHM, .before = AUC)

llr_ridge_avg_results
```

## 9. Penalized Linear Logistic Regression: LASSO

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
llr_lasso_results <- cross_validate(
   cv_partitions = data_partitions_ml, 
   learner = penalized_learner, 
   evaluator = compute_evaluation_criteria,
   penalty = 1,
   shinyProgress = FALSE)
```

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
llr_lasso_avg_results <- llr_lasso_results %>%
   dplyr::select(AUC, GINI, PCC, BS, KS) %>%
   colMeans() %>%
   dplyr::bind_rows() %>%
   dplyr::mutate(LEARNING_ALGORITHM = "LINEAR LR (LASSO)") %>%
   dplyr::relocate(LEARNING_ALGORITHM, .before = AUC)

llr_lasso_avg_results
```

## 10. Penalized Linear Logistic Regression: Adaptive LASSO

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
llr_alasso_results <- cross_validate(
   cv_partitions = data_partitions_ml, 
   learner = penalized_learner, 
   evaluator = compute_evaluation_criteria,
   penalty = 2,
   shinyProgress = FALSE)
```

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
llr_alasso_avg_results <- llr_alasso_results %>%
   dplyr::select(AUC, GINI, PCC, BS, KS) %>%
   colMeans() %>%
   dplyr::bind_rows() %>%
   dplyr::mutate(LEARNING_ALGORITHM = "LINEAR LR (ADAPTIVE LASSO)") %>%
   dplyr::relocate(LEARNING_ALGORITHM, .before = AUC)

llr_alasso_avg_results
```

## 11. Penalized Non-Linear Logistic Regression: RIDGE

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
nllr_ridge_results <- cross_validate(
   cv_partitions = data_partitions_nllr, 
   learner = penalized_learner, 
   evaluator = compute_evaluation_criteria,
   penalty = 0,
   shinyProgress = FALSE)
```

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
nllr_ridge_avg_results <- nllr_ridge_results %>%
   dplyr::select(AUC, GINI, PCC, BS, KS) %>%
   colMeans() %>%
   dplyr::bind_rows() %>%
   dplyr::mutate(LEARNING_ALGORITHM = "NON-LINEAR LR (RIDGE)") %>%
   dplyr::relocate(LEARNING_ALGORITHM, .before = AUC)

nllr_ridge_avg_results
```

## 12. Penalized Non-Linear Logistic Regression: LASSO

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
nllr_lasso_results <- cross_validate(
   cv_partitions = data_partitions_nllr, 
   learner = penalized_learner, 
   evaluator = compute_evaluation_criteria,
   penalty = 1,
   shinyProgress = FALSE)
```

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
nllr_lasso_avg_results <- nllr_lasso_results %>%
   dplyr::select(AUC, GINI, PCC, BS, KS) %>%
   colMeans() %>%
   dplyr::bind_rows() %>%
   dplyr::mutate(LEARNING_ALGORITHM = "NON-LINEAR LR (LASSO)") %>%
   dplyr::relocate(LEARNING_ALGORITHM, .before = AUC)

nllr_lasso_avg_results
```

## 13. Penalized Non-Linear Logistic Regression: Adaptive LASSO

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
nllr_alasso_results <- cross_validate(
   cv_partitions = data_partitions_nllr, 
   learner = penalized_learner, 
   evaluator = compute_evaluation_criteria,
   penalty = 2,
   shinyProgress = FALSE)
```

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
nllr_alasso_avg_results <- nllr_alasso_results %>%
   dplyr::select(AUC, GINI, PCC, BS, KS) %>%
   colMeans() %>%
   dplyr::bind_rows() %>%
   dplyr::mutate(LEARNING_ALGORITHM = "NON-LINEAR LR (ADAPTIVE LASSO)") %>%
   dplyr::relocate(LEARNING_ALGORITHM, .before = AUC)

nllr_alasso_avg_results
```

# Comparing Performance

Summary results:

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
summary_results <- dplyr::bind_rows(
   pltr_alasso_avg_results,
   pltr_lasso_avg_results,
   pltr_ridge_avg_results,
   rf_avg_results,
   svm_radial_avg_results,
   svm_polynomial_avg_results,
   llr_avg_results,
   llr_ridge_avg_results,
   llr_lasso_avg_results,
   llr_alasso_avg_results,
   nllr_ridge_avg_results,
   nllr_lasso_avg_results,
   nllr_alasso_avg_results
)

summary_results %>%
   dplyr::arrange(dplyr::desc(AUC))
```

By AUC:

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
summary_results %>%
   dplyr::mutate(
      LEARNING_ALGORITHM = factor(LEARNING_ALGORITHM, 
                                  levels = LEARNING_ALGORITHM[order(AUC)])
   ) %>%
   ggplot(aes(x = LEARNING_ALGORITHM, y = AUC)) +
   geom_bar(stat = "identity", fill = "#f68060", alpha = .6, width = .4) +
   coord_flip() +
   xlab("") +
   ylab("AUC") +
   theme_bw()
```

By PCC:

```{r, echo=TRUE, cache=TRUE, warning=FALSE}
summary_results %>%
   dplyr::mutate(
      LEARNING_ALGORITHM = factor(LEARNING_ALGORITHM, 
                                  levels = LEARNING_ALGORITHM[order(PCC)])
   ) %>%
   ggplot(aes(x = LEARNING_ALGORITHM, y = PCC)) +
   geom_bar(stat = "identity", fill = "#f68060", alpha = .6, width = .4) +
   coord_flip() +
   xlab("") +
   ylab("PCC") +
   theme_bw()
```






